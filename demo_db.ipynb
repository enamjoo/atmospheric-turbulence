{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "96d6bdba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from turbStats import tilt_mat, corr_mat, get_r0\n",
    "from simulator import Simulator\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import torch\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d165ba47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "# Select device and set patameters\n",
    "device = torch.device('cuda:0') if torch.cuda.is_available() else torch.device('CPU')\n",
    "\n",
    "D = 0.1    # aperture diameter \n",
    "r0 = 0.1  # fried parameter set to [0.1, 0.05, 0.1/3, 0.025, 0.02] for turbulence of [1,2,3,4,5]\n",
    "turbulence_strength = D/r0\n",
    "print(turbulence_strength)\n",
    "\n",
    "# Generate correlation matrix for tilt. Do this once for each different turbulence parameter. \n",
    "L = 3000\n",
    "im_size = 112 # image size in DB\n",
    "tilt_mat(im_size, D, r0, L)\n",
    "\n",
    "# Load Simulator\n",
    "simulator = Simulator(turbulence_strength, im_size).to(device, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "848cdf9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 2413/12000 [00:10<00:40, 238.11it/s]"
     ]
    }
   ],
   "source": [
    "# Apply turbulence to the entire dataset\n",
    "database = 'agedb'\n",
    "data_path = './images/{}'.format(database)\n",
    "output_path = './images/{}_turbulence_{}'.format(database, turbulence_strength)\n",
    "if not os.path.exists(output_path):\n",
    "    os.makedirs(output_path)\n",
    "    \n",
    "image_list = os.listdir(data_path)\n",
    "for image_name in tqdm(image_list):\n",
    "    image = plt.imread(os.path.join(data_path, image_name))\n",
    "\n",
    "    image = image / 255.0\n",
    "    if len(image.shape) == 3: \n",
    "        image = image.transpose((2,0,1))\n",
    "    image = torch.tensor(image, device = device, dtype=torch.float32)\n",
    "\n",
    "    # Note that the current version does not support batched images. Only one frame at a time. \n",
    "    out_image = simulator(image).detach().cpu().numpy()\n",
    "\n",
    "    if len(out_image.shape) == 3: \n",
    "        out_image = out_image.transpose((1,2,0))\n",
    "\n",
    "    # save image\n",
    "    out_image_path = os.path.join(output_path, image_name)\n",
    "    out_image = np.clip(out_image, 0, 1.0)\n",
    "    plt.imsave(out_image_path, out_image)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
